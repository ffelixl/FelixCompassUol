# Sprint 07

### Orientador(a): Dilmara Caroline

Na sprint 07, foram abordados os conceitos de hadoop e spark!

## Learn By Example: Hadoop, MapReduce for Big Data problems - Principais pontos abordados:

* Introdução ao Hadoop:
Explanação sobre a necessidade de ferramentas como o Hadoop para lidar com grandes volumes de dados.
Visão geral do ecossistema Hadoop e suas principais componentes.

* Configuração do Ambiente Hadoop:
Instruções práticas sobre como configurar um ambiente Hadoop local para desenvolvimento e teste.

* Programação MapReduce:
Profundização no paradigma de programação MapReduce, que é central para o processamento de dados distribuído no Hadoop.
Compreensão dos conceitos de mapeamento e redução para resolver problemas complexos de Big Data.

* Desenvolvimento de Aplicações MapReduce:
Exemplos práticos de desenvolvimento de aplicações MapReduce para resolver problemas específicos.
Abordagem de casos de uso do mundo real para ilustrar como a programação MapReduce pode ser aplicada.

* Otimização de Desempenho:
Estratégias e práticas recomendadas para otimizar o desempenho das aplicações MapReduce.
Discussão sobre como lidar com grandes conjuntos de dados de maneira eficiente.

* Compreensão do Fluxo de Trabalho do Hadoop:
Exploração do fluxo de trabalho típico de um trabalho Hadoop, desde a ingestão de dados até a saída dos resultados.

* Estudo de Caso: Aplicações Práticas:
Apresentação de estudos de caso práticos, mostrando como o Hadoop e o MapReduce são aplicados em situações do mundo real.

* Desafios e Soluções:
Abordagem de desafios comuns enfrentados ao lidar com Big Data e como o Hadoop fornece soluções para esses desafios.

## Formação Spark com Pyspark – Principais ponto abordados:

* Introdução ao Apache Spark:
Visão geral do Apache Spark e suas capacidades para processamento de dados em larga escala.
Compreensão da arquitetura Spark e dos principais conceitos, como RDDs (Resilient Distributed Datasets).

* Configuração do Ambiente PySpark:
Instruções práticas sobre como configurar um ambiente de desenvolvimento PySpark.
Configuração de clusters Spark para processamento distribuído.


* Programação em PySpark:
Fundamentos da programação PySpark usando Python como linguagem principal.
Exploração de operações de transformação e ação em RDDs e DataFrames.

* Trabalhando com DataFrames:
Utilização de DataFrames, uma abstração de alto nível no Spark, para manipulação eficiente de dados.
Exploração das funcionalidades de consultas e operações SQL-like no PySpark.
Processamento de Dados Estruturados e Semiestruturados:

* Processamento de Dados Estruturados e Semiestruturados:
Abordagem sobre como PySpark lida com dados estruturados e semiestruturados.
Utilização de ferramentas como Spark SQL para consultas complexas.

* Otimização de Desempenho:
Estratégias para otimizar o desempenho de trabalhos PySpark.
Compreensão de práticas recomendadas e ajustes de configuração.

Na subpasta evidencias estará todos os prints de respostas das atividades e a realização das mesmas!!
Na subpasta exercicios estará os scripts das atividades e outros arquivos necessários

* [Pasta Evidencias](https://github.com/ffelixl/FelixCompassUol/tree/main/Sprint%2006/evidencias)
* [Pasta Exercicios]()

### Certificados

* [Conclusão do curso 01](https://github.com/ffelixl/FelixCompassUol/blob/main/Sprint%2006/certificados/certificado%2001.pdf)


